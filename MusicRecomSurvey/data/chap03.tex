\subsection{传统推荐算法——协同过滤}
\subsubsection{推荐问题的形式化描述}
对推荐任务进行数学形式的描述\cite{ItemCF}：
\begin{itemize}
    \item 用户集$U =\{u_1, u_2, \cdots, u_m\}$表示推荐系统的用户
    \item 内容集$C = \{c_1, c_2, \cdots, c_n\}$表示备选的内容
    \item 评分$p_{i, j}$表示用户$u_i$对于内容$c_j$给出的评价经过量化之后的值
    \item 已评价集合$C_i \subset   C$表示用户已经对于一部分内容给出过评分，这部分评分构成的集合。所有的这些集合构成的集合为$\mathcal{C} = \{C_1, C_2, \cdots, C_m\}$
    \item 基于上面的输入，对于一个特定的用户$u_a$，我们的推荐算法要给出该用户对应的评分预测值$\hat p_{a, j}$，以及推荐集合$C_{a}^r$
    \item 评分预测值$\hat p_{a, j}$表示对于用户$u_a$，其对于内容$c_j$未给出评价，即$c_j \not \in C_{a}$，所以其评价$p_{a, j}$的值是未知的，所以要给出一个基于已知数据的估计值$\hat p_{a, j} $来对于这个评分进行估计，所有这些估计量构成集合$P_a = 
    \{\hat p_{a, i}|c_i\in C - C_a,\}$
    \item 推荐集合$C_a^r = \{c_i|c_i\in C - C_a, \hat p_{a, i} \in top_N(P_a)\}$
\end{itemize}

综上，可以看出推荐算法的核心工作就是对于用户未进行评价的内容进行评估，估计用户对于该项内容的评分，然后按照这些估计出的评分给出推荐集合。之后的推荐算法的内容也是基本围绕如何对于未知评分进行估计而展开的。

\subsubsection{协同过滤的基本思想}
协同过滤是一种被广泛运用的传统推荐方法，或者说是一套算法框架。在此框架下，算法根据数据来源，处理对象，按照不同的方法对于问题进行处理，形成了一系列基于协同过滤的方法。例如对于用户数据进行分析得到的User-based的算法，对于内容进行分析得到的Item-based的方法，以及将这些分析进行综合汇总，得到的混合方法\cite{CFSurvey}。这些具体的算法将在后续的章节中进行更加详细的介绍和总结，在这里首先对于协同过滤的算法框架进行综述说明。

首先，协同过滤的方法建立在如下的假设上：

\textbf{假设1}：$P_{i, j}$的分布不是均匀的。

\textbf{假设2}：$u_i$与$u_j$相似，则$p_{i, k} \approx p_{j, k}$。

先讨论假设1的合理性，由上面的问题背景，可以看出推荐系统的使用环境，必须满足的条件就是用户存在对内容选择的偏向性。如果在用户对内容的选择没有偏向性，则一个随机的推荐系统和经过推荐算法处理得到的的系统将是效用相同的。所以通过假设1，设定用户对于不同内容的评价不均匀，即定义了其偏向性。这样的假设对于推荐系统是合理的。

对于假设2，其是否成立无法给出完全准确的说明，但是根据我们日常生活中的经验，这样的假设可以认为是成立的。

在此基础上，协同过滤的思想可以表述为：使用与目标用户相似的用户的评分数据，或者与目标内容相似内容的评分数据，根据其相似程度，对目标用户对于目标内容的评分进行估计。

可以看出协同过滤将推荐问题转化为两个子问题：如何确定两个用户或者两项内容之间的相似程度，以及如何通过相似个体给出目标用户对目标内容的评分\cite{CFSurvey}。下面也将根据处理对象的不同，将协同过滤分类进行讨论。

\subsubsection{基于用户的方法}
\paragraph{评分估计模型}
基于用户的方法表示利用不同用户之间的相似关系，借助目标用户已经产生的评分数据，与其他的用户进行比较，产生用户之间的相似性。根据相似用户产生相似评分的假设，相似用户对于目标内容的评分，来估计目标用户对于目标内容的评分\cite{UserCF}。

对于用户$u_i$，其对于$C_i$中的内容已经给出过评分，所以可以定义其评分的均值为：

\begin{equation}
    \bar p_i = \frac{1}{|C_i|}\sum_{c_j \in C_i}p_{i, j}
\end{equation}

接下来，对于目标用户$u_a$，估计其对于目标内容的评分$\hat p_{a, j}$：

\begin{equation}
    \hat p_{a,j} = \bar p_a + k \sum_{i=1}^n w(a,i)(p_{i,j}-\bar p_i)
\end{equation}

其中$k$为一项标准化参数，来对于其他用户的影响进行调整；$w(a, j)$为定义的用户距离，表示用户之间的相似程度\cite{UserCF}。至此，除了相似度之外，其他的参数我们都能从已知数据中直接得到了，所以之后的主要任务就是定义用户之间的相似程度$w(i, j)$。

\paragraph{用户相似性}
对于用户这样一个抽象的概念求相似程度是一件比较难下手的任务，但是当前的任务是求解用户在特定的评分任务上的相似程度，所以一个自然的想法是比较两个用户在共同评过分的内容上评分结果的相似程度，来比较两个用户评分行为的相似程度。这样就将问题转化为了一个求解向量之间相似性的问题：定义$C_{ij} = C_i \cap C_j$为两者共同评过分的内容集合，定义$v_i$，$v_j$为两人对于$C_{ij}$中内容的评分，可以按照如下的方法定义相似程度：

余弦距离法：利用两评分向量在空间中的夹角的余弦值大小来表征两者的相似性。
\begin{equation}
    w(i, j) = \frac{v_i \cdot v_j}{\|v_i\|\|v_j\|}
\end{equation}

相关系数法：利用随机向量的相关系数表示相似性\cite{CorrWeight}。
\begin{equation}
    w(i, j) = \frac{\sum_k (v_{ik} - \bar v_i)(v_{jk} - \bar v_j)}{\sqrt{\sum_k (v_{ik} - \bar v_i)^2} \sqrt{\sum_k (v_{jk} - \bar v_j)^2}}
\end{equation}

词向量法：在词频统计模型中，使用了一种方式来定义两文档中词频向量的相似性，在这里也可以将文档对应于用户，词汇对应于内容，词频对应于评分，使用这种词频向量相似性的方法来计算用户之间的相似性\cite{FreqVector}。
\begin{equation}
    w(i, j) = \sum_{k} \frac{v_{ik}}{\sqrt{\sum_{c_s \in C_i}v_{is}^2}} \frac{v_{jk}}{\sqrt{\sum_{c_s \in C_j}v_{js}^2}}
\end{equation}

\paragraph{模型优化}
经过上面的讨论，已经完成了基于用户的协同过滤方法的构建。但是不难发现其中有一些值得改进的部分。比如在计算用户的相似性上，我们只是使用了两个用户共同评分的集合$C_{ij} = C_{i} \cap C_{j}$，但是这种方法可能会丢弃掉大量的评分数据，所以对已知数据的利用是并不充分的\cite{CorrWeight}。同时，仅仅通过这样一个较小的集合，对于用户在全局上的评分行为进行描述，很有可能是不准确的。所以一个解决方案是降低这些小集合带来的影响，比如如果两个用户之间评分集合的交集大小小于一个阈值则降低其权重。另一种方法是利用默认值对一些被“丢弃”掉的内容进行预填充，从而能够扩展使用到的数据范围，基于更加大的数据范围，对于用户的评分行为进行更加精准的描述。对于填充值的选择必须是简单的，否则会很大地影响算法的效率，同时这种估计的精度本身也不能达到很高，所以过分地在这里追求精准度本身就是不划算的。常见的默认填充值选取方法有：在一个小组内对于用户的评分进行简单的扩展，使用中性或者负面评分作为默认值进行填充等\cite{DefaultVote}。

在讨论相似性的过程中，我们讨论了一种基于词频向量的相似性表达，同样，我们也可以参考词频分析中的相关概念，提出逆用户频率(Inverse User Frequency)的概念\cite{FreqVector}。首先定义逆频率$f_j = log(\frac{n}{n_j})$，其中$n_j$为对内容$c_j$评分的用户数，再在相似度的计算中引入该参数：
\begin{align}
    w(i, j) &= \frac{\sum_{k}f_k\sum_{k}f_k v_{ik}v_{jk} - (\sum_{k}f_k v_{ik})(\sum_{k}f_k v_{jk})}{\sqrt{UV}}\\
    U &= \sum_{k}f_k (\sum_{k}f_k v_{ik}^2 - (\sum_{k}f_k v_{ik})^2)\\
    V &= \sum_{k}f_k (\sum_{k}f_k v_{jk}^2 - (\sum_{k}f_k v_{jk})^2)
\end{align}
此时，$f_k$可以认为是对于评分进行的一次加权，对于拥有更高$f_k$值的内容，在计算相似度中会提供更大的权重。能够削弱那些不准确数据带来的影响。

此外，在对于权重值进行估计时，我们可能会更关注于与目标用户相关性较高的用户，而对于那些不那么相关的用户，反而可能会造成实验结果的更大误差。所以另外一种优化模型的方法是Case Amplification，将估计得到的权重进行进一步的变换\cite{UserCF}：
\begin{equation}
    w'(i,j) = w(i,j) \cdot |w(i, j)|^{\rho - 1},\rho > 1 
\end{equation}
这种变换能够使较小的权重更加趋近于0，削减其影响，同时较大的权重能够保持其接近于1的性质，体现出较大的作用。

\subsubsection{基于内容的方法}
在基于用户的模型基础上，一个想法是很自然的，能否通过对于内容相似性进行讨论，来对于评分进行估计。这就是基于内容的方法了\cite{ItemCF}。由于其思想与上面的基于用户的方法有很多的相似之处，所以这里就相对简单地对于这种方法进行介绍。

\paragraph{评分估计模型}
与基于用户的方法相似，这里使用用户对于其他内容的评分，来对于未评价内容的评分进行预测。而其他已评价内容与未评价内容之间也需要定义相似性$w(i, j)$表示$c_i$和$c_j$之间的相似程度。之后可以通过不同的方式对于未知评分进行估计，例如加权和\cite{ItemCF}：
\begin{equation}
    \hat p_{u, i} = \frac{\sum_{similar items, j}w(i, j)p_{u, j}}{\sum_{similar items, j}|w(i, j)|}
\end{equation}
或者在加权和的基础上，不直接使用原始数据$p_{i, j}$，而是通过线性回归模型，对这一值进行近似处理。对于目标内容$c_i$和相似内容$c_j$，线性回归模型可以表示为\cite{ItemCF}：
\begin{equation}
    \bar p'_j = \alpha \bar p_i + \beta + \epsilon
\end{equation}

\paragraph{内容相似性}
首先将内容转化为评分向量。对于两内容$c_i$和$c_j$，找到一个用户集$U_{ij}$，其中的用户对于两内容均进行过评价，得到该用户集对于两项内容的打分向量，就可以将内容转化为向量的表达形式。之后求解向量相似度的方法与上面的用户方法是通用的。

\subsubsection{基于模型的方法}
基于模型的方法与上面的方法有一定的差别——上面基于用户和基于内容的方法均很大程度上依赖于根据观测到的数据直接去估计，但是基于模型的方法是先利用数据生成一个特定模型，在根据这个模型的相关性质来对于未知的评分数据进行估计\cite{CFSurvey}，常见的模型有如下几种：
\paragraph{贝叶斯模型}
使用基于朴素贝叶斯的思想，将该问题抽象为一个分类任务。同时，分类任务的类别必须是分立的，所以需要将评分设置为离散值，每一个评分值对应于一个类别，这样就能满足分类任务的条件。根据朴素贝叶斯分类算法\cite{NaiveBayes}，先求出内容被分到每一类中的概率，再通过比较若干概率值的大小，找到概率最高的类别，并将其作为预测分类。计算的方法如下：
\begin{align}
    &class = \mathop{argmax}_{j \in classSet} p(class_j)\prod_{o}P(X_o = x_o|class_j)\\
    &P(X_i = x_i|class_j) = \frac{\#(X_i = x_i, class_j) + 1}{\#(class_j) + \#{X_i}|}
\end{align}

在朴素贝叶斯模型的基础上，能够进行进一步的改进以提高其性能。例如使用扩展逻辑回归模型ELR，一种基于最大化对数条件似然的参数学习方法\cite{ELR}，与贝叶斯模型相结合得到TAN-ELR(tree argumented naive Bayes)和NB-ELR(naive Bayes optimized by ELR)\cite{ELR}，这些方法能够带来更高的分类准确度，但是需要付出更多的模型训练时间。还有方法可以将贝叶斯网和决策树在节点上进行组合，贝叶斯网上每个节点都有一个对应的决策树，来解释评分的情况\cite{UserCF}。

\paragraph{聚类模型}
聚类模型的主要功能是对于样本进行整合，得到若干个类别。常见的方法有k-means，DBSCAN，OPTICS，BIRCH等\cite{Cluster}。聚类模型可以用于对于已知的数据像是用户或者内容进行预处理，但是其本身并不承担有对于评分进行预测的功能。所以通常的做法是将其与之前的基于用户或者内容的方法结合起来使用。例如基于评分用户，对于不同的内容进行聚类；基于评分内容，对于评分用户进行聚类；再根据评分或者被评分数量进行进一步的聚类，经过这种初始化后，得到的数据在根据上面基于用户和内容的方法进行处理。另一种模型是FMM(flexible mixture model)，将用户和内容同时进行聚类，允许其属于多个类别中，分别对于用户和内容的聚类进行处理，得到了比传统基于用户方法更好的结果\cite{FMM}。

聚类方法的优点在于通过对于原始数据进行预处理，使得一些预测能够在更小的范围内进行，而非整个数据内。但是它的推荐质量并不算好，还需要投入大量的时间到聚类计算当中。

\paragraph{回归模型}
在上面基于用户的方法中，在一些特殊的情况下，两个评分的向量虽然有很高的相似性，但是其欧式距离可能会比较远，所以在这样的基础上，得到的预测值是有较大偏差的。所以基于回归模型的预测模型能够较好地满足我们对于评分预测的需求。设$X=(X_1, X_2, \cdots, X_n)$为表示用户对于不同内容偏好的随机变量，设置线性回归模型为：
\begin{equation}
    Y = \Gamma X + N
\end{equation}
其中$\Gamma$为参数矩阵，$N$为用户选择过程中的噪声，$Y = [Y_{ij}]$为评分矩阵，$Y_{ij}$表示用户$u_i$对于内容$c_j$的评分值。所以矩阵$Y$中存在一些未知的数据，可以认为其为稀疏的，这就造成了一个问题，无法利用$Y$与$X$对于回归模型中的参数进行求解，而无法求解出参数的模型自然是没有太大用处的。一种解决方法是先利用默认的值对于$Y$进行填充，再将该结果作为初始值，使用EM算法，对于模型进行逐步逼近\cite{Regression}。

\subsubsection{混合方法}
对于上面列举的一系列方法，不难看出这些方法虽然从多个角度，多种方法对于推荐问题进行了解答，但是基本上用到的都只是单纯的用户评分数据，但是在实践当中，我们对于用户还有很多其他外源性的数据可供使用，例如用户的性别、年龄、兴趣爱好等以及内容的分类，具体内容以及形式等。这些信息均能够用于对于用户行为进行更加准确的推测，从而更有效地实现推荐系统\cite{CBCF}，但是在上面的方法中并没有对这些信息进行更加深入的使用。所以在构建推荐系统的过程中，我们可能需要在先前的基础上，发展基于用户背景的，基于内容上下文的，基于知识背景的推荐，将这些内容综合考虑来构建推荐系统。这里将这种综合考虑各方面信息的方法统一称为混合方法\cite{Hybrid}。

\paragraph{外部特征方法内嵌}
这部分混合方法将外部的特征信息内嵌到协同过滤的过程当中，从而增强其相应功能，比较成功的尝试有：
\begin{itemize}
    \item Content-boosted CF\cite{ContentBoost}：通过构造贝叶斯分类器，根据外部特征进行分类，再根据其分类情况进行评分预测。这种方法能够将对于用户评分的估计限定到一个大小较小的合理的子集当中，从而降低计算复杂度，减小干扰，提高准确性。
    \item 贝叶斯倾向模型\cite{BayesPreference}：根据采集到的用户信息，通过MCMC的方法对于决策模型进行采样和推断，构造出一个相应的倾向模型。
    \item 使用外部特征给出用户的描述，再根据CF给出描述相似的用户，最后给出相应的推荐\cite{ProfilePreference}。
    \item 过滤器模型\cite{Agent}：根据用户外部特征为其设置一系列过滤器，每一种过滤器会保留一部分满足特征性质的内容，而丢掉剩下的内容。最后留下满足用户特征的内容用于推荐。
\end{itemize}

\paragraph{基于用户与模型方法的组合}
一个很简单的思路就是将上面基于模型和基于用户的方法组合起来。
例如PMCF(Probabilistic memory-based and collaborative filtering )技术\cite{PMCF}，
将用户的外部特征构建用户评分的后验分布，并基于此分布对于用户的评分进行预测。这种方法为了解决新用户冷启动的问题，会对于用户的信息进行额外的查找。为了节省计算时间，这种方法也通过选取子集的方式来对于评分进行估计。这种方法能够比普通的基于用户的方法以及基于贝叶斯模型的方法取得更高的准确率。

另一种可能的方法是PD(Personality diagnosis)\cite{PD}，这种方法将目标用户视作在其他随机选取的用户基础上添加高斯噪声得到的，根据目标用户的已知评分，我们可以计算出目标用户与其他用户相同的偏好的概率，以及他或她喜欢某一内容的概率。这种方法可以看作是对于用户进行了每组包含一个样本的聚类。最终这种方法得到了比单纯基于用户的模型，以及基于聚类，基于贝叶斯网等基于模型的方法更好的结果。

\paragraph{协同过滤方法与其他推荐系统的组合}
对于协同过滤方法，一个绕不开的问题就是其冷启动的问题：目标用户的评分数据很少，导致无法找到足够多的样本为其提供参考。所以此时，如果有其他的推荐系统为协同过滤系统提供参考，就可以在发生冷启动时不过分依赖于不那么准确的协同过滤方法，而是使用其他推荐系统的结果。一种常见的方法是为多种推荐系统之间设置一定的权重，这种权重是根据用户的外部特征，通过对于一些条件进行判别得到的动态变化的值。当用户面临冷启动时，能够降低协同过滤结果所占有的比重，而更多地参考其他推荐系统得到的结果\cite{Hybrid}。